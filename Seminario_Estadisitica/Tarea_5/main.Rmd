---
author: "Fernando Alvarado"
date: "2025-03-12"
output: html_document
---


```{r setup, include=FALSE}
#Empezamos limpiando nuestro ambiente
rm(list = ls(all.names = TRUE))


# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
	echo = FALSE,
	fig.align = "center",
	fig.dim = c(5.0, 4.0),
	fig.pos = "H",
#Agregamos configuraciones para evitar mensajes de advertencias y de errores en el archivo
	message = FALSE,
	warning = FALSE,
	error = F
)



# Librerías
library(dplyr)      # Para el manejo de datos
library(ggplot2)    # Para realizar gráficas
library(kableExtra) # Para un mejor manejo de tablas
library(GGally)     # Para realizar análisis descriptivo fácilmente
library(multcomp)   # Para pruebas de hipótesis
library(car)        # Para funciones útiles de modelos de regresión lineal múltiple
library(broom)      # Para obtener los residuales estandarizados
library(purrr)      # Para la función map y map2
library(lmtest )    #Checar homoceasticidad
library(nortest )


# Para purebas de hipotesis





#Extrayendo nuestra data
setwd("C:/Users/ferna/Documents/Estadistica_Aplicada/Seminario_Estadisitica/Tarea_4/Data")

data <- read.csv("./initech.csv")




```

```{r summary}
#Convirtiendo nuestro sumary a otro formato para poder trabajar mas facil con el 
resumen <- as.data.frame(t(as.matrix(summary(data))))
```


# Años de experiencia vs Salario 


En este trabajo, modelaremos la relación entre los años de experiencia y el salario que percibe cada trabajador de la empresa. En una revisión rápida de los datos, observamos que el salario máximo fue de: `r resumen$Freq[12]` , mientras que el mínimo fue de: `r resumen$Freq[2]`. Además, el trabajador promedio ganaba: `r resumen$Freq[8]`, con una media de: `r resumen$Freq[7]` años de experiencia.



```{r Grafica_Datos}
ggplot(data, aes(y= salary, x = years))+
  geom_point(color = "blue")
```
__Esta gráfica nos brinda una primera impresión sobre la distribución de nuestros datos.__


Al aplicar un modelo de regresión, observamos que no se cumplían los supuestos requeridos, por lo que plantearemos un modelo de regresión logística. Para definir la transformación adecuada, utilizaremos la metodología de Box-Tidwell, que nos permitirá determinar la potencia óptima para los datos y los pesos, concluyendo que la variable x debe elevarse a la potencia de 1.83.


```{r Prueba_box,  results="hide"}
box <- boxTidwell(salary ~years, data = data) 
#Ho No se necita una tranformacion
#Ha El coeficiente de la transformacion de la variable es distinta de 0, se recomienda una transformacion 
box
```


Con esta prueba de hipótesis, concluimos que es necesario aplicar una transformación a x con un exponente de 1.83 para que los datos cumplan con los supuestos y mejoren nuestro AIC. Para ello, generaremos una secuencia de valores para probar distintas transformaciones en x y determinar el peso óptimo para nuestro modelo.


```{r Algoritmo_minimos}
#Funciones a usar ---------------------

minimo = function(list, n, exit){#
 if(n==0 || length(list)==0){
    return(exit)
 }else {
    exit = c(exit, min(list))  #Haciendo nuestro vector de salida con los numero mas pequeños
    list = list[list!=min(list)] #Quitando el numero minimo de la lista, aunque esten repetidos
    return(minimo(list, n-1, exit))
    
 }
}

#-----------------------

#Secuancia que vamos a usar para hacer nuestra malla

posib_pot <- seq(.1,2.5,.05)
posib_cov <- seq(1,2.5,.05)

#Hace todas las combinaciones
combinaciones <- expand.grid(x = posib_pot, y = posib_cov)



# Aplicar la función a todas las combinaciones
AIC_Mods <- apply(expand.grid(posib_pot, posib_cov), 1, function(par) {
  AIC(lm(salary ~ I(years^par[2]), data = data, weights = 1 / I(years^par[1])))
})


# Haciendo un Df, para poder trabajar con nuestros modelos
Resultado_Modelos <- data.frame(combinaciones, AIC = unlist(AIC_Mods))


minimos <- minimo(Resultado_Modelos$AIC, 3, c()) #Funcion para cehar los minos AICs que tenemos en nuestro modelo

#Seleccionando las variables para neustro modelo 

n <- 5  # Cambia según lo que necesites

# Ordenar los valores de AIC y seleccionar los n más pequeños
indices_minimos <- order(Resultado_Modelos$AIC)[1:n]

# Crear un data frame con los n valores mínimos de AIC y sus respectivos parámetros
df_minimos <- Resultado_Modelos[indices_minimos, ]


 


```

#### Revisando los tres modelos con el menor AIC:  `r minimos`.

A continuación, imprimimos nuestros cinco mejores modelos, donde x representa el peso de la regresión y y la potencia a la que debe elevarse x.


```{r}

library(knitr)



# Imprimir tabla con kable()
kable(df_minimos, caption = "Resultados del modelo con menor AIC")


```
 __Donde Y representa las potencias y X representa las covarianzas.__

#### Modelo propuesto

```{r Grafica_Modelos}
modelo1 <- lm(salary ~ I(years^df_minimos$y[1]), data = data, weights = 1 / I(years^df_minimos$x[1]))





# 1. Crear las predicciones usando el modelo ponderado
data$prediccion <- predict(modelo1, newdata = data)

# 2. Graficar los puntos originales y la línea ajustada manualmente
ggplot(data, aes(x = years, y = salary)) +
  geom_point() +  # Puntos reales
   geom_smooth(method = "lm", se = FALSE, color = "green") +
  geom_line(aes(y = prediccion), color = "red", size = 1) +  # Línea de regresión ponderada
  labs(title = "Salario vs Años de Experiencia (Regresión Ponderada)",
       x = "Años de Experiencia",
       y = "Salario") +
  theme_minimal()


```
__En esta gráfica, podemos observar que nuestro modelo de regresión logística (línea roja) se ajusta mejor a los datos y los describe con mayor precisión en comparación con la recta de regresión (línea verde).__




## Verifiquemos si nuestra regresion ponderada pasa los supuestos:


#### Verificando linealidad 

```{r, echo=FALSE,  results="hide"}
crPlots(modelo1)
residualPlots(modelo1, test = TRUE, plot = FALSE) #Test para verificar si el modelo es lineal o no H0 = La relacion entre el predictor y la respuesta e lina vs HA: La relacion no es lineal

```


Usando una prueba de hipótesis y una gráfica del paquete car, podemos concluir que existe suficiente evidencia estadística para afirmar la linealidad, con un p-value de 0.426.



#### Verificando homoceasticidad 

```{r, echo=FALSE,  results="hide"}
plot(modelo1, 3)
car::ncvTest(modelo1)  #Ho, la variaza de los errores es contante va HA, la varianza no es contante
#lmtest::bptest(modelo1) 
```

Usando la librería car y la gráfica generada en R, podemos concluir que existe suficiente evidencia estadística para afirmar la homocedasticidad en nuestros datos, con un p-value de 0.41787.




#### Vamos a checar si hay normalidad en nuestros datos

```{r, echo=FALSE,  results="hide"}
qqPlot(residuals(modelo1))

ks.test(residuals(modelo1), "pnorm", mean(residuals(modelo1)), sd(residuals(modelo1)))


#ad.test(residuals(modelo1))

```
Usando la prueba de hipótesis de la librería nortest, podemos concluir que los datos siguen una distribución normal, con un p-value de 0.3856.




#### Autocorrelación en los residuos

```{r,  results="hide"}

bgtest(modelo1)
```

Con una prueba Breusch-Godfrey, podemos concluir que existe suficiente evidencia estadística para verificar la autocorrelación de residuos en modelos de regresión ponderada, con un p-value de 0.2302.




---
author: "Fernando Alvarado"
date: "2025-03-12"
output: html_document
---


```{r setup, include=FALSE}
#Empezamos limpiando nuestro ambiente
rm(list = ls(all.names = TRUE))


# Configuración global de los bloques de código (chunk's)
knitr::opts_chunk$set(
	echo = FALSE,
	fig.align = "center",
	fig.dim = c(5.0, 4.0),
	fig.pos = "H",
#Agregamos configuraciones para evitar mensajes de advertencias y de errores en el archivo
	message = FALSE,
	warning = FALSE,
	error = F
)


# Librerías para manipulación de datos y análisis estadístico
library(dplyr)       # Manejo de datos
library(kableExtra)  # Mejor manejo de tablas
library(GGally)      # Análisis descriptivo fácil
library(multcomp)    # Pruebas de hipótesis
library(broom)       # Residuales estandarizados y modelos de regresión
library(purrr)       # Funciones map y map2
library(lmtest)      # Pruebas de hipótesis y homocedasticidad
library(nortest)     # Pruebas de normalidad
library(car)         # Diagnóstico de modelos de regresión
library(MVN)         # Multinormalidad
library(ICSNP)       # Pruebas de hipótesis Hotelling
library(here)        # Manejo de rutas de archivos
library(MASS)  # Para distribuciones multivariadas
library(Hotelling)  # Para pruebas de Hotelling
library(ICSNP)      #Pureba t hotelling y multivariado 

# Librerías para visualización de datos
library(ggplot2)     # Gráficos
library(ggthemes)    # Temas para ggplot2
library(scatterplot3d) # Gráficos 3D
#library(expn)        # Gráficos exploratorios
library(plotly)      # Gráficos interactivos
library(gridExtra)   # Mostrar múltiples gráficos








```



```{r Data}
#Extrayendo nuestra data
setwd("C:/Users/ferna/Documents/Estadistica_Aplicada/Analisis_Multivariado/Tarea_2/Data")

datos <- read.table("./cork.txt", header=TRUE, sep=" ", fileEncoding="UTF-8")
datosWine <- read.table("./wine.txt", header=TRUE, sep=",", fileEncoding="UTF-8")



```



# Ejecicio 9 


En los datos Cork tenemos 4 columnas: N, E, S y W, cuyas medias son: `r unname(summary(datos$N)["Mean"])`, `r unname(summary(datos$E)["Mean"])`, `r unname(summary(datos$S)["Mean"])` y `r unname(summary(datos$W)["Mean"])`. Las medianas respectivas son: `r unname(summary(datos$N)["Median"])`, `r unname(summary(datos$E)["Median"])`, `r unname(summary(datos$S)["Median"])` y `r unname(summary(datos$W)["Median"])`. Esto nos ofrece una perspectiva sobre cómo se distribuyen nuestros datos.



### Checando normalidad por columna

```{r}
#El dos en apply nos dice sobre donde vamos a palicar la funcion 1 es para filas y dos es para colunas
prueba_individual <-  apply(datos, 2, function(x) shapiro.test(x)$p.value)  #H₀ (Hipótesis nula): Los datos siguen una distribución normal. vs H₁ (Hipótesis alternativa): Los datos no siguen una distribución normal.

```

Usando la prueba Shapiro-Wilk con un valor p de 0.05, obtuvimos que para N, E y S existe suficiente evidencia estadística para concluir que no se distribuyen de forma normal, ya que rechazamos Ho con valores p de:  `r unname(prueba_individual[1])`,  `r unname(prueba_individual[2]) `,  `r unname(prueba_individual[3]) `. La única para la cual no tenemos evidencia suficiente para rechazar la normalidad es W, con un valor p de:  `r unname(prueba_individual[4]) `.


```{r}

# Crear QQ-plots en ggplot2
plot_qq <- function(data, col_name) {
  ggplot(data, aes(sample = .data[[col_name]])) +
    stat_qq() +
    stat_qq_line(color = "#d35400", size = 1) +
    labs(title = paste("QQ-Plot de", col_name), x = "Cuantiles teóricos", y = "Cuantiles muestrales") +
    theme_minimal()
}

# Generar gráficos para cada variable
qq_plots <- lapply(names(datos), function(col) plot_qq(datos, col))

# Mostrar en una sola impresión
grid.arrange(grobs = qq_plots, ncol = 2, nrow = 2)

```

A partir de los QQ-Plots, observamos que las variables N, E y S se desvían significativamente de una distribución normal, ya que presentan colas pesadas (curtosis elevada). Esto indica una mayor presencia de valores extremos o atípicos en comparación con una distribución normal. Además, los puntos en los QQ-Plots no siguen la línea de referencia esperada (línea naranja), lo que sugiere que la distribución subyacente difiere de la normal. Por otro lado, la variable W muestra un mejor ajuste a la distribución normal, con una menor cantidad de valores atípicos.



```{r,   results="hide"}
# Realizar la prueba de Mardia
mardia_test <- mvn(data = datos, mvnTest = "mardia")
print(mardia_test$multivariateNormality)

# Realizar la prueba de Henze-Zirkler
hz_test <- mvn(data = datos, mvnTest = "hz")
print(hz_test$multivariateNormality)

# Realizar la prueba de Royston
royston_test <- mvn(data = datos, mvnTest = "royston")
print(royston_test$multivariateNormality)




```

```{r texto}
# Extraer los valores del data frame sin nombres
valores <- unname((mardia_test$multivariateNormality)[[3]])

# Convertir a una sola línea de texto
texto_final <- paste(na.omit(valores), collapse = ", ")


```



#### Prueba de normalidad multivariada 



Para realizar el test de normalidad hicimos tres pruebas de hipótesis: Mardia, Henze-Zirkler y Royston, de las cuales:

Según la prueba de Mardia, aceptamos estadísticamente que nuestros datos se distribuyen de forma normal multivariada, con valores p de: `r texto_final`, donde el primer valor corresponde a la prueba Mardia Skewness y el segundo a la prueba Mardia Kurtosis. Por lo tanto, concluimos que existe evidencia de normalidad en los datos.

Sin embargo, según la prueba Henze-Zirkler con un valor p de `r unname((hz_test$multivariateNormality)[3])`, y la prueba Royston con un valor p de `r unname((royston_test$multivariateNormality)[3])`, no tenemos suficiente evidencia estadística para concluir normalidad. Esto podría deberse al reducido número de observaciones (28), lo que limita la potencia estadística de las pruebas.





```{r}
mardia_test <- mvn(data = datos, mvnTest = "mardia", multivariatePlot = "qq")
```

Mediante nuestra gráfica y la prueba de Mardia, podemos concluir que estadísticamente nuestros datos siguen una distribución normal, aunque estamos siendo flexibles debido al reducido número de observaciones.

# Ejercicio 10 


### Inciso i)

__Probar la hipiotesis nula de que el vino promedio difiera de 13.15 grados de alcohol y 2.5 unidades de aacido malico.__

```{r}

library(ICSNP)

# Definir los datos y la media hipotética
mu0 <- c(13.15, 2.5)  # Valores hipotéticos de referencia
x <- datosWine[, c("Alcohol", "Malic_acid")]  # Subset con las variables de interés

# Prueba de Hotelling T² de una muestra
proof<- HotellingsT2(x - matrix(mu0, nrow = nrow(x), ncol = length(mu0), byrow = TRUE))

```


 
 Al realizar una prueba de Hotelling T², obtenemos que no existe evidencia estadística suficiente para concluir que el vino promedio difiera significativamente de 13.15 grados de alcohol y 2.5 unidades de ácido málico, con un valor p de  `r proof$p.value` .
 


### Inciso ii)

__Realizar los contrastes de hipiotesis necesarios para verificar si existe o no una diferencia para los niveles de alcohol y acido malico para las clases 1 y 2 de vinos.__

```{r}

group1 <- datosWine[datosWine$Class == 1, c("Alcohol", "Malic_acid")]
group2 <- datosWine[datosWine$Class == 2, c("Alcohol", "Malic_acid")]

proof_hot <- hotelling.test(group1, group2)



```


Al realizar una prueba de hipótesis de Hotelling para contrastar esta hipótesis, concluimos que estadísticamente no existe diferencia en los niveles de alcohol y ácido málico entre las clases 1 y 2 de vinos, con un valor p de `r unname(proof_hot$pval)`.





```{r}
# Calcular las medias de cada grupo
medias <- datosWine %>%
  group_by(Class) %>%
  summarise(Alcohol = mean(Alcohol), Malic_acid = mean(Malic_acid))

# Graficar los puntos individuales
ggplot(datosWine, aes(x = Alcohol, y = Malic_acid, color = as.factor(Class))) +
  geom_point(alpha = 0.5) +  # Puntos de datos individuales con transparencia
  # Agregar las medias como puntos más grandes
  geom_point(data = medias, aes(x = Alcohol, y = Malic_acid, color = as.factor(Class)), 
             size = 5, shape = 7, stroke = 2) +  # Estrella para las medias
  scale_color_manual(values = c("#2874a6", "#0e6655", "#d35400")) +  # Personalizar colores
  labs(color = "Clase") +
  theme_minimal()
```


El valor `r unname(proof_hot$pval)` resulta un poco curioso en nuestra prueba de hipótesis. Para analizarlo mejor, utilizamos la gráfica anterior, en la que presentamos un diagrama de dispersión y añadimos las medias de cada grupo (cuadros).
